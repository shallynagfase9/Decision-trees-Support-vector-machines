{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZX24LlRWLKV2wvANbQ6NH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Decision-trees-Support-vector-machines/blob/main/Support_Vector_Machines_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
        "algorithms?"
      ],
      "metadata": {
        "id": "2vqRcOk4lTjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning, particularly in the context of Support Vector Machines (SVM) and other kernel-based methods, polynomial functions and kernel functions have a significant relationship. Kernel functions allow algorithms to operate in a high-dimensional space without explicitly mapping data points to that space, which can be computationally expensive. This is known as the \"kernel trick.\"A polynomial function in machine learning typically refers to a mapping of input features into a higher-dimensional space using polynomial terms."
      ],
      "metadata": {
        "id": "hUXcXKxLlWI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
      ],
      "metadata": {
        "id": "K1IDLz6alndu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "# Example data (replace with your data)\n",
        "X = np.array([[0, 0], [1, 1]])\n",
        "y = np.array([0, 1])\n",
        "# Create SVM classifier with polynomial kernel\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X, y)\n",
        "# Example prediction (replace with your prediction)\n",
        "print(clf.predict([[2., 2.]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2SWxkeVntcy",
        "outputId": "853eb4aa-5dc0-493b-ea20-a2cf1013dd46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
      ],
      "metadata": {
        "id": "hyrSodnJmTPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the value of epsilon in Support Vector Regression (SVR) typically results in a larger tube around the regression line (or hyperplane in higher dimensions). This larger tube allows more training points to be within the margin defined by epsilon without penalty."
      ],
      "metadata": {
        "id": "DyZqYkiKmHSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
        "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
        "and provide examples of when you might want to increase or decrease its value?"
      ],
      "metadata": {
        "id": "BWGlIAScmU-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of kernel function, C parameter, epsilon parameter, and gamma parameter in SVR significantly impacts model performance, complexity, and generalization ability. Careful tuning based on the specific characteristics of the dataset and the problem at hand is crucial for achieving optimal results."
      ],
      "metadata": {
        "id": "JGDa6B-jmu5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Assignment:\n",
        "L Import the necessary libraries and load the dataseg\n",
        "L Split the dataset into training and testing setZ\n",
        "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
        "L Create an instance of the SVC classifier and train it on the training datW\n",
        "L hse the trained classifier to predict the labels of the testing datW\n",
        "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
        "precision, recall, F1-scoreK\n",
        "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
        "improve its performanc_\n",
        "L Train the tuned classifier on the entire dataseg\n",
        "L Save the trained classifier to a file for future use."
      ],
      "metadata": {
        "id": "0hup6U-ZoBUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create SVC classifier instance\n",
        "svc = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Train the classifier on the scaled training data\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = svc.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate performance using accuracy score and classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf', 'linear', 'poly'],\n",
        "    'degree': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and best score found by GridSearchCV\n",
        "print(\"Best Parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Best Accuracy Score found by GridSearchCV:\")\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "best_svc = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Save the trained classifier to a file using joblib\n",
        "joblib.dump(best_svc, 'svm_classifier.pkl')\n",
        "print(\"Classifier saved to svm_classifier.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeuvFt-moOIt",
        "outputId": "697a8b29-73c1-46d4-bda3-fd41c1f64229"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       1.00      0.95      0.98        43\n",
            "      benign       0.97      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Best Parameters found by GridSearchCV:\n",
            "{'C': 0.1, 'degree': 2, 'gamma': 1, 'kernel': 'linear'}\n",
            "Best Accuracy Score found by GridSearchCV:\n",
            "0.9736263736263737\n",
            "Classifier saved to svm_classifier.pkl\n"
          ]
        }
      ]
    }
  ]
}